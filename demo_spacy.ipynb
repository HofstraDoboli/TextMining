{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HofstraDoboli/TextMining/blob/main/demo_spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0hequ6Zdlb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdabda81-26c9-4048-8f40-d537478516bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-28 17:14:55.387066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-28 17:14:57.115640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmfdTwZVdlcB",
        "outputId": "95a2c0b1-7fd8-4120-9dee-715d06acd31f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "402\n",
            "('NEW YORK -- Twenty-three years ago, Serena Williams won her first Grand Slam '\n",
            " 'title here. On Friday, she said her goodbyes in the same place, in front of '\n",
            " 'a sold-out crowd at Arthur Ashe Stadium.\\n'\n",
            " '\"Thank you daddy, I know you\\'re watching. Thanks mom,\" Williams said before '\n",
            " 'starting to cry during her post-match on-court interview. \"Everyone that\\'s '\n",
            " 'here, that\\'s been on my side, for so many years, decades\"')\n"
          ]
        }
      ],
      "source": [
        "# read the mobydick.txt file\n",
        "# f = open('mobydick.txt', 'r')\n",
        "# text = f.read()  # reads all file\n",
        "from pprint import pp\n",
        "text = '''NEW YORK -- Twenty-three years ago, Serena Williams won her first Grand Slam title here. On Friday, she said her goodbyes in the same place, in front of a sold-out crowd at Arthur Ashe Stadium.\n",
        "\"Thank you daddy, I know you're watching. Thanks mom,\" Williams said before starting to cry during her post-match on-court interview. \"Everyone that's here, that's been on my side, for so many years, decades\"'''\n",
        "print(len(text))\n",
        "pp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU_-JoYVdlcC",
        "outputId": "fbf5f4a1-7b01-4a75-a839-a5c1cbdb2f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
            "['tagger', 'attribute_ruler', 'lemmatizer', 'ner']\n"
          ]
        }
      ],
      "source": [
        "# https://spacy.io/usage/spacy-101#whats-spacy\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "print(nlp.pipe_names)\n",
        "nlp.disable_pipes('tok2vec', 'parser') # 'ner')\n",
        "print(nlp.pipe_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rxH-hOWddlcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e953f74-7299-4a3d-9fc9-f7f76b420253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000000\n"
          ]
        }
      ],
      "source": [
        "print(nlp.max_length)\n",
        "#nlp.max_length = len(text)  # increase the size of the text that nlp accepts\n",
        "tokens = nlp(text) # processes the text according to the pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj3I5FdHdlcD",
        "outputId": "028aabf0-20ca-4b66-826c-75630c4eee32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srM4cdOTdlcE",
        "outputId": "9a112890-e653-48e4-91ea-2b874be4bad9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "type(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in tokens:\n",
        "  print(f\"{t.text} \\t {t.lemma_} \\t {t.pos_} \\t {t.tag_} \\t {t.is_stop} \\t {t.is_alpha}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "_evFhBfSRpdi",
        "outputId": "2a46ef2b-2659-47af-845a-da70c76a30f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'spacy.tokens.token.Token' object has no attribute 'label_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-873d6e6474fa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{t.text} \\t {t.lemma_} \\t {t.pos_} \\t {t.tag_} \\t {t.is_stop} \\t {t.is_alpha} \\t {t.label_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'label_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in tokens.ents: # entities\n",
        "  print(f\"{t.text} \\t {t.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSekcDT4dduy",
        "outputId": "c9ebeb0a-4d4d-40bb-d488-7b448ae09a5a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW YORK \t GPE\n",
            "Twenty-three years ago \t DATE\n",
            "Serena Williams \t PERSON\n",
            "first \t ORDINAL\n",
            "Grand Slam \t ORG\n",
            "Friday \t DATE\n",
            "Arthur Ashe Stadium \t FAC\n",
            "Williams \t PERSON\n",
            "so many years \t DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract all lemmatized tokens that are not stop words"
      ],
      "metadata": {
        "id": "6y7RGY3QS9oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "for word in tokens.ents:\n",
        "  if word.label_ in [\"PERSON\", \"GPE\", \"ORG\",\"FAC\"]: # len(word_tokenize(word.text)) > 1\n",
        "    print(word.text,word.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTJPQJdueorU",
        "outputId": "a4baced6-4078-497a-ae9c-935c2502c008"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW YORK GPE\n",
            "Serena Williams PERSON\n",
            "Grand Slam ORG\n",
            "Arthur Ashe Stadium FAC\n",
            "Williams PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvGbZpVNdlcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f1a255-3d36-4b57-f276-63392608908f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('new york', 'new york'),\n",
              " ('years', 'year'),\n",
              " ('ago', 'ago'),\n",
              " ('serena williams', 'serena williams'),\n",
              " ('won', 'win'),\n",
              " ('first', 'first'),\n",
              " ('grand slam', 'grand slam'),\n",
              " ('title', 'title'),\n",
              " ('here', 'here'),\n",
              " ('friday', 'friday'),\n",
              " ('said', 'say'),\n",
              " ('goodbyes', 'goodbye'),\n",
              " ('same', 'same'),\n",
              " ('place', 'place'),\n",
              " ('front', 'front'),\n",
              " ('sold', 'sell'),\n",
              " ('crowd', 'crowd'),\n",
              " ('arthur ashe stadium', 'arthur ashe stadium'),\n",
              " ('thank', 'thank'),\n",
              " ('daddy', 'daddy'),\n",
              " ('know', 'know'),\n",
              " ('watching', 'watch'),\n",
              " ('thanks', 'thank'),\n",
              " ('mom', 'mom'),\n",
              " ('williams', 'williams'),\n",
              " ('said', 'say'),\n",
              " ('starting', 'start'),\n",
              " ('cry', 'cry'),\n",
              " ('post', 'post'),\n",
              " ('match', 'match'),\n",
              " ('court', 'court'),\n",
              " ('interview', 'interview'),\n",
              " ('here', 'here'),\n",
              " ('side', 'side'),\n",
              " ('so', 'so'),\n",
              " ('many', 'many'),\n",
              " ('years', 'year'),\n",
              " ('decades', 'decade')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "words_spacy = []\n",
        "start_prop_noun = False\n",
        "\n",
        "for t in tokens:\n",
        "  if t.pos_ in [\"NOUN\", \"PROPN\", \"ADV\", \"ADJ\", \"VERB\"]:\n",
        "    if t.is_alpha: # words with just letters\n",
        "      if t.pos_ == \"PROPN\":\n",
        "        if not start_prop_noun:\n",
        "          start_prop_noun = True\n",
        "          prop_noun = t.text.lower()\n",
        "        else:\n",
        "          prop_noun += ' ' + t.text.lower()\n",
        "      elif start_prop_noun:\n",
        "          start_prop_noun = False\n",
        "          words_spacy.append((prop_noun, prop_noun))\n",
        "          prop_noun = \"\"\n",
        "\n",
        "      if not start_prop_noun:\n",
        "        words_spacy.append((t.text.lower(), t.lemma_.lower()))\n",
        "\n",
        "words_spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czu-y_XImu9F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}