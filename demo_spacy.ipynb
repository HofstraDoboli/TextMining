{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HofstraDoboli/TextMining/blob/main/demo_spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D0hequ6Zdlb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a1b14e-f505-45c7-e30f-cdce4fb0e138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmfdTwZVdlcB",
        "outputId": "d97e44a2-2ff4-45b6-f4d5-89107ca6ac94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "402\n",
            "('NEW YORK -- Twenty-three years ago, Serena Williams won her first Grand Slam '\n",
            " 'title here. On Friday, she said her goodbyes in the same place, in front of '\n",
            " 'a sold-out crowd at Arthur Ashe Stadium.\\n'\n",
            " '\"Thank you daddy, I know you\\'re watching. Thanks mom,\" Williams said before '\n",
            " 'starting to cry during her post-match on-court interview. \"Everyone that\\'s '\n",
            " 'here, that\\'s been on my side, for so many years, decades\"')\n"
          ]
        }
      ],
      "source": [
        "# read the mobydick.txt file\n",
        "# f = open('mobydick.txt', 'r')\n",
        "# text = f.read()  # reads all file\n",
        "from pprint import pp\n",
        "text = '''NEW YORK -- Twenty-three years ago, Serena Williams won her first Grand Slam title here. On Friday, she said her goodbyes in the same place, in front of a sold-out crowd at Arthur Ashe Stadium.\n",
        "\"Thank you daddy, I know you're watching. Thanks mom,\" Williams said before starting to cry during her post-match on-court interview. \"Everyone that's here, that's been on my side, for so many years, decades\"'''\n",
        "print(len(text))\n",
        "pp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU_-JoYVdlcC",
        "outputId": "26d92839-dfa6-495a-ddcf-15fd313166d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
            "['tagger', 'attribute_ruler', 'lemmatizer', 'ner']\n"
          ]
        }
      ],
      "source": [
        "# https://spacy.io/usage/spacy-101#whats-spacy\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "print(nlp.pipe_names)\n",
        "nlp.disable_pipes('tok2vec', 'parser') # 'ner')\n",
        "print(nlp.pipe_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rxH-hOWddlcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb9b86c-164b-4dee-c271-6b4088514cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000000\n"
          ]
        }
      ],
      "source": [
        "print(nlp.max_length)\n",
        "#nlp.max_length = len(text)  # increase the size of the text that nlp accepts\n",
        "tokens = nlp(text) # processes the text according to the pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj3I5FdHdlcD",
        "outputId": "028aabf0-20ca-4b66-826c-75630c4eee32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srM4cdOTdlcE",
        "outputId": "9a112890-e653-48e4-91ea-2b874be4bad9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "type(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in tokens:\n",
        "  print(f\"{t.text} \\t {t.lemma_} \\t {t.pos_} \\t {t.tag_} \\t {t.is_stop} \\t {t.is_alpha}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_evFhBfSRpdi",
        "outputId": "87cb9e8c-e480-4e9e-d6a5-d91e4248ce13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW \t new \t NOUN \t NN \t False \t True\n",
            "YORK \t york \t NOUN \t NN \t False \t True\n",
            "-- \t -- \t NOUN \t NN \t False \t False\n",
            "Twenty \t twenty \t NOUN \t NN \t True \t True\n",
            "- \t - \t NOUN \t NN \t False \t False\n",
            "three \t three \t NOUN \t NN \t True \t True\n",
            "years \t years \t NOUN \t NN \t False \t True\n",
            "ago \t ago \t NOUN \t NN \t False \t True\n",
            ", \t , \t NOUN \t NN \t False \t False\n",
            "Serena \t serena \t NOUN \t NN \t False \t True\n",
            "Williams \t williams \t NOUN \t NN \t False \t True\n",
            "won \t won \t NOUN \t NN \t False \t True\n",
            "her \t her \t NOUN \t NN \t True \t True\n",
            "first \t first \t NOUN \t NN \t True \t True\n",
            "Grand \t grand \t NOUN \t NN \t False \t True\n",
            "Slam \t slam \t NOUN \t NN \t False \t True\n",
            "title \t title \t NOUN \t NN \t False \t True\n",
            "here \t here \t NOUN \t NN \t True \t True\n",
            ". \t . \t NOUN \t NN \t False \t False\n",
            "On \t on \t NOUN \t NN \t True \t True\n",
            "Friday \t friday \t NOUN \t NN \t False \t True\n",
            ", \t , \t NOUN \t NN \t False \t False\n",
            "she \t she \t NOUN \t NN \t True \t True\n",
            "said \t said \t NOUN \t NN \t False \t True\n",
            "her \t her \t NOUN \t NN \t True \t True\n",
            "goodbyes \t goodbyes \t NOUN \t NN \t False \t True\n",
            "in \t in \t NOUN \t NN \t True \t True\n",
            "the \t the \t NOUN \t NN \t True \t True\n",
            "same \t same \t NOUN \t NN \t True \t True\n",
            "place \t place \t NOUN \t NN \t False \t True\n",
            ", \t , \t NOUN \t NN \t False \t False\n",
            "in \t in \t NOUN \t NN \t True \t True\n",
            "front \t front \t NOUN \t NN \t True \t True\n",
            "of \t of \t NOUN \t NN \t True \t True\n",
            "a \t a \t NOUN \t NN \t True \t True\n",
            "sold \t sold \t NOUN \t NN \t False \t True\n",
            "- \t - \t NOUN \t NN \t False \t False\n",
            "out \t out \t NOUN \t NN \t True \t True\n",
            "crowd \t crowd \t NOUN \t NN \t False \t True\n",
            "at \t at \t NOUN \t NN \t True \t True\n",
            "Arthur \t arthur \t NOUN \t NN \t False \t True\n",
            "Ashe \t ashe \t NOUN \t NN \t False \t True\n",
            "Stadium \t stadium \t NOUN \t NN \t False \t True\n",
            ". \t . \t NOUN \t NN \t False \t False\n",
            "\n",
            " \t \n",
            " \t SPACE \t _SP \t False \t False\n",
            "\" \t \" \t NOUN \t NN \t False \t False\n",
            "Thank \t thank \t NOUN \t NN \t False \t True\n",
            "you \t you \t NOUN \t NN \t True \t True\n",
            "daddy \t daddy \t NOUN \t NN \t False \t True\n",
            ", \t , \t NOUN \t NN \t False \t False\n",
            "I \t i \t NOUN \t NN \t True \t True\n",
            "know \t know \t NOUN \t NN \t False \t True\n",
            "you \t you \t NOUN \t NN \t True \t True\n",
            "'re \t 're \t NOUN \t NN \t True \t False\n",
            "watching \t watching \t NOUN \t NN \t False \t True\n",
            ". \t . \t NOUN \t NN \t False \t False\n",
            "Thanks \t thanks \t NOUN \t NN \t False \t True\n",
            "mom \t mom \t NOUN \t NN \t False \t True\n",
            ", \t , \t NOUN \t NN \t False \t False\n",
            "\" \t \" \t NOUN \t NN \t False \t False\n",
            "Williams \t williams \t NOUN \t NN \t False \t True\n",
            "said \t said \t NOUN \t NN \t False \t True\n",
            "before \t before \t NOUN \t NN \t True \t True\n",
            "starting \t starting \t NOUN \t NN \t False \t True\n",
            "to \t to \t NOUN \t NN \t True \t True\n",
            "cry \t cry \t NOUN \t NN \t False \t True\n",
            "during \t during \t NOUN \t NN \t True \t True\n",
            "her \t her \t NOUN \t NN \t True \t True\n",
            "post \t post \t NOUN \t NN \t False \t True\n",
            "- \t - \t NOUN \t NN \t False \t False\n",
            "match \t match \t NOUN \t NN \t False \t True\n",
            "on \t on \t NOUN \t NN \t True \t True\n",
            "- \t - \t NOUN \t NN \t False \t False\n",
            "court \t court \t NOUN \t NN \t False \t True\n",
            "interview \t interview \t NOUN \t NN \t False \t True\n",
            ". \t . \t NOUN \t NN \t False \t False\n",
            "\" \t \" \t NOUN \t NN \t False \t False\n",
            "Everyone \t everyone \t PRON \t NN \t True \t True\n",
            "that \t that \t NOUN \t NN \t True \t True\n",
            "'s \t 's \t NOUN \t NN \t True \t False\n",
            "here \t here \t NOUN \t NN \t True \t True\n",
            ", \t , \t NOUN \t NN \t False \t False\n",
            "that \t that \t NOUN \t NN \t True \t True\n",
            "'s \t 's \t NOUN \t NN \t True \t False\n",
            "been \t been \t NOUN \t NN \t True \t True\n",
            "on \t on \t NOUN \t NN \t True \t True\n",
            "my \t my \t NOUN \t NN \t True \t True\n",
            "side \t side \t NOUN \t NN \t True \t True\n",
            ", \t , \t NOUN \t NN \t False \t False\n",
            "for \t for \t NOUN \t NN \t True \t True\n",
            "so \t so \t NOUN \t NN \t True \t True\n",
            "many \t many \t NOUN \t NN \t True \t True\n",
            "years \t years \t NOUN \t NN \t False \t True\n",
            ", \t , \t NOUN \t NN \t False \t False\n",
            "decades \t decades \t NOUN \t NN \t False \t True\n",
            "\" \t \" \t NOUN \t NN \t False \t False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in tokens.ents: # entities\n",
        "  print(f\"{t.text} \\t {t.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSekcDT4dduy",
        "outputId": "a59e399d-2b10-40be-d035-16fd52d38e3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW YORK \t GPE\n",
            "Twenty-three years ago \t DATE\n",
            "Serena Williams \t PERSON\n",
            "first \t ORDINAL\n",
            "Grand Slam \t ORG\n",
            "Friday \t DATE\n",
            "Arthur Ashe Stadium \t FAC\n",
            "Williams \t PERSON\n",
            "so many years \t DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract all lemmatized tokens that are not stop words"
      ],
      "metadata": {
        "id": "6y7RGY3QS9oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "for word in tokens.ents:\n",
        "  if word.label_ in [\"PERSON\", \"GPE\", \"ORG\",\"FAC\"]: # len(word_tokenize(word.text)) > 1\n",
        "    print(word.text,word.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTJPQJdueorU",
        "outputId": "2aa4eaf4-b733-40d4-c28d-baf153f30fa5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW YORK GPE\n",
            "Serena Williams PERSON\n",
            "Grand Slam ORG\n",
            "Arthur Ashe Stadium FAC\n",
            "Williams PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvGbZpVNdlcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f1a255-3d36-4b57-f276-63392608908f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('new york', 'new york'),\n",
              " ('years', 'year'),\n",
              " ('ago', 'ago'),\n",
              " ('serena williams', 'serena williams'),\n",
              " ('won', 'win'),\n",
              " ('first', 'first'),\n",
              " ('grand slam', 'grand slam'),\n",
              " ('title', 'title'),\n",
              " ('here', 'here'),\n",
              " ('friday', 'friday'),\n",
              " ('said', 'say'),\n",
              " ('goodbyes', 'goodbye'),\n",
              " ('same', 'same'),\n",
              " ('place', 'place'),\n",
              " ('front', 'front'),\n",
              " ('sold', 'sell'),\n",
              " ('crowd', 'crowd'),\n",
              " ('arthur ashe stadium', 'arthur ashe stadium'),\n",
              " ('thank', 'thank'),\n",
              " ('daddy', 'daddy'),\n",
              " ('know', 'know'),\n",
              " ('watching', 'watch'),\n",
              " ('thanks', 'thank'),\n",
              " ('mom', 'mom'),\n",
              " ('williams', 'williams'),\n",
              " ('said', 'say'),\n",
              " ('starting', 'start'),\n",
              " ('cry', 'cry'),\n",
              " ('post', 'post'),\n",
              " ('match', 'match'),\n",
              " ('court', 'court'),\n",
              " ('interview', 'interview'),\n",
              " ('here', 'here'),\n",
              " ('side', 'side'),\n",
              " ('so', 'so'),\n",
              " ('many', 'many'),\n",
              " ('years', 'year'),\n",
              " ('decades', 'decade')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "words_spacy = []\n",
        "start_prop_noun = False\n",
        "\n",
        "for t in tokens:\n",
        "  if t.pos_ in [\"NOUN\", \"PROPN\", \"ADV\", \"ADJ\", \"VERB\"]:\n",
        "    if t.is_alpha: # words with just letters\n",
        "      if t.pos_ == \"PROPN\":\n",
        "        if not start_prop_noun:\n",
        "          start_prop_noun = True\n",
        "          prop_noun = t.text.lower()\n",
        "        else:\n",
        "          prop_noun += ' ' + t.text.lower()\n",
        "      elif start_prop_noun:\n",
        "          start_prop_noun = False\n",
        "          words_spacy.append((prop_noun, prop_noun))\n",
        "          prop_noun = \"\"\n",
        "\n",
        "      if not start_prop_noun:\n",
        "        words_spacy.append((t.text.lower(), t.lemma_.lower()))\n",
        "\n",
        "words_spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czu-y_XImu9F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}