{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "1MhhkiLQFUi7B9-3uU4ETHUXRMFFbp4ZU",
      "authorship_tag": "ABX9TyM06r71objKj9NOaa75KVSL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HofstraDoboli/TextMining/blob/main/encoder_classification_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wAYQ-1ZuT5f"
      },
      "outputs": [],
      "source": [
        "pip install -U \"transformers[torch]\" datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text classification reuters dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from pprint import pprint\n",
        "from datasets import Dataset\n",
        "\n",
        "train_data    = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), shuffle=True)\n",
        "test_all_data = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), shuffle=True)\n",
        "\n",
        "train_ds    = Dataset.from_dict({\"text\": train_data.data, \"label_id\": train_data.target})\n",
        "test_all_ds = Dataset.from_dict({\"text\": test_all_data.data, \"label_id\": test_all_data.target})"
      ],
      "metadata": {
        "id": "9Ss35SHgucXC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(train_data)) # data = text, target = number between 0 and 19\n",
        "print(max(train_data.target)) # numeric label, train.target_names = actual name of the data\n",
        "print(train_data.data[0]) # the actual text\n",
        "print(len(train_data.data)) # length of the data - number of samples\n",
        "print(type(train_data.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJcY59I_wrlD",
        "outputId": "7cc98cbe-2a9d-4f0d-918b-f898a6fcd3cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DESCR', 'data', 'filenames', 'target', 'target_names']\n",
            "19\n",
            "I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "11314\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6b1f411",
        "outputId": "17ef3fd8-faea-4fa1-8f88-d32e4922aff2"
      },
      "source": [
        "# Split the test_all data into validation and testing data\n",
        "test_all_split = test_all_ds.train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "val_ds  = test_all_split['train']\n",
        "test_ds = test_all_split['test']\n",
        "\n",
        "# Print the sizes of the new sets\n",
        "print(f\"Validation set size: {len(val_ds)}\")\n",
        "print(f\"Testing set size: {len(test_ds)}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set size: 3766\n",
            "Testing set size: 3766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# detect all labels\n",
        "labels = train_data.target_names\n",
        "num_labels = len(labels)\n",
        "print(labels)\n",
        "print(num_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAAoy95swTuZ",
        "outputId": "9ad5f112-3f96-4521-f4ff-306dac681bc2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i: name for i, name in enumerate(labels)}\n",
        "label2id = {name: i for i, name in enumerate(labels)}\n"
      ],
      "metadata": {
        "id": "XuZ6bOxWtZxA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, ClassLabel\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import AutoConfig, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "MODEL_NAME = \"distilbert/distilbert-base-uncased\"   # <-- replace with \"bert-base\", \"albert-base-v2\", \"distilbert/distilbert-base-cased\", \"roberta-base\", \"microsoft/deberta-v3-base\", etc.\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True) # use_fast = uses a tokenizer written in Rust, much faster than the default one in Transformers\n",
        "\n",
        "# Configure model for\n",
        "config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
        "config.id2label = id2label\n",
        "config.label2id = label2id\n",
        "print(config)"
      ],
      "metadata": {
        "id": "5oXf9mZkvDky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 256\n",
        "def preprocess(data):\n",
        "    return tokenizer(data[\"text\"], truncation=True) # max_length = max_length)\n",
        "\n",
        "train_token = train_ds.map(preprocess, batched=True) # remove_columns = \"text\") # batch_size=64,\n",
        "val_token   = val_ds.map(preprocess, batched=True) # remove_columns = \"text\")\n",
        "test_token  = test_ds.map(preprocess, batched=True) #remove_columns = \"text\")"
      ],
      "metadata": {
        "id": "ZWGOvT3Xe-uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename column\n",
        "train_token = train_token.rename_column(\"label_id\", \"labels\")\n",
        "val_token = val_token.rename_column(\"label_id\", \"labels\")\n",
        "test_token = test_token.rename_column(\"label_id\", \"labels\")"
      ],
      "metadata": {
        "id": "gdvNlWJCmaUH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yR5iIZ0jEKv",
        "outputId": "5db28a07-553c-4616-b1fd-cc5455d9f87c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 3766\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_token['input_ids'][0][:20])\n",
        "print(val_token['input_ids'][0][-20:])\n",
        "\n",
        "print(val_token['attention_mask'][0][:20])\n",
        "print(val_token['attention_mask'][0][-20:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuNd0j5v9jg9",
        "outputId": "fa98ccbb-9594-4490-a8f6-67b254e055b1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1011, 1008, 1011, 1011, 1011, 1011, 2521, 2013, 2108, 1000, 7463, 2041, 1010, 1000, 1996, 24131, 2024, 2579, 1010]\n",
            "[2515, 1996, 3793, 3073, 3350, 1029, 1996, 18707, 1997, 1996, 8771, 1997, 1996, 24404, 18774, 2072, 1010, 3839, 1997, 102]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Metrics\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "# Load metrics\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"precision_macro\": precision.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
        "        \"recall_macro\": recall.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
        "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
        "        \"precision_weighted\": precision.compute(predictions=preds, references=labels, average=\"weighted\")[\"precision\"],\n",
        "        \"recall_weighted\": recall.compute(predictions=preds, references=labels, average=\"weighted\")[\"recall\"],\n",
        "        \"f1_weighted\": f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"],\n",
        "    }\n"
      ],
      "metadata": {
        "id": "v4HMRoqsoq1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    # ðŸ“‚ Directory where all checkpoints, logs, and the final model are saved\n",
        "    output_dir = \"out\",\n",
        "\n",
        "    # How often to evaluate on the validation set\n",
        "    # \"epoch\" â†’ run evaluation after each full pass over the training data\n",
        "    eval_strategy = \"epoch\",\n",
        "\n",
        "    # When to save model checkpoints\n",
        "    # \"epoch\" â†’ save after each epoch; can also be \"steps\" to save every N steps\n",
        "    save_strategy=\"epoch\",\n",
        "\n",
        "    # Initial learning rate for AdamW optimizer\n",
        "    learning_rate=2e-5,   # typical for BERT/DeBERTa/RoBERTa fine-tuning\n",
        "\n",
        "    # Training and evaluation batch sizes (per device, not total)\n",
        "    per_device_train_batch_size = 32,\n",
        "    per_device_eval_batch_size  = 64,\n",
        "\n",
        "    # Number of epochs (full dataset passes)\n",
        "    num_train_epochs = 3,\n",
        "\n",
        "    # Weight decay (L2 regularization on model parameters)\n",
        "    # helps prevent overfitting\n",
        "    weight_decay = 0.01,\n",
        "\n",
        "    # Automatically reload the best model checkpoint at the end of training\n",
        "    load_best_model_at_end = True,\n",
        "\n",
        "    # Which metric to monitor for best-model selection\n",
        "    # Should match one of the keys returned by `compute_metrics`\n",
        "    metric_for_best_model = \"f1_macro\",\n",
        "\n",
        "    # âš¡ Use 16-bit (half-precision) floating point on GPUs that support it\n",
        "    # Greatly speeds up training and reduces memory usage\n",
        "    fp16 = True,\n",
        "\n",
        "    # Whether to push checkpoints to the Hugging Face Hub automatically\n",
        "    push_to_hub = False,\n",
        "\n",
        "    # Disable logging to Weights & Biases and other services\n",
        "    report_to = \"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "IskSYzOZpKj5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "WzY3wGd-jAjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use datacollator - faster\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer)"
      ],
      "metadata": {
        "id": "G72DAXSON6ZZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model\n",
        "config.problem_type = \"single_label_classification\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7POs0KRLquln",
        "outputId": "df4cf1f2-1b10-42d8-8456-bf442d8f9cbc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Trainer\n",
        "from transformers import Trainer, AutoTokenizer\n",
        "\n",
        "trainer = Trainer(\n",
        "    # The model to fine-tune\n",
        "    # This should be an instance of a model class such as AutoModelForSequenceClassification\n",
        "    model= model,\n",
        "\n",
        "    # All hyperparameters and training settings\n",
        "    # This includes learning rate, batch size, number of epochs, fp16, etc.\n",
        "    args = training_args,\n",
        "\n",
        "    # Dataset used for training\n",
        "    # Should be a Hugging Face Dataset (or DatasetDict[\"train\"])\n",
        "    train_dataset = train_token,\n",
        "\n",
        "    # ðŸ§ª Dataset used for evaluation\n",
        "    # The Trainer automatically runs evaluation at the intervals defined in TrainingArguments\n",
        "    eval_dataset = val_token,\n",
        "\n",
        "    # Tokenizer associated with your model\n",
        "    # Ensures that new data or predictions can be encoded/decoded correctly\n",
        "    # Use processing_class instead of tokenizer in newer versions of transformers\n",
        "    processing_class = tokenizer, #AutoTokenizer,\n",
        "\n",
        "    # Function that computes evaluation metrics (accuracy, f1, etc.)\n",
        "    # The Trainer calls this after each evaluation step and logs the results\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "TR4hTOp9r_EW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Train\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "01j-39yCsEV3",
        "outputId": "13734e73-2397-41e3-a27c-f82d3b1e1cad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1062' max='1062' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1062/1062 04:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.013361</td>\n",
              "      <td>0.703133</td>\n",
              "      <td>0.684195</td>\n",
              "      <td>0.685142</td>\n",
              "      <td>0.677552</td>\n",
              "      <td>0.698435</td>\n",
              "      <td>0.703133</td>\n",
              "      <td>0.694960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.677800</td>\n",
              "      <td>1.025231</td>\n",
              "      <td>0.704992</td>\n",
              "      <td>0.693955</td>\n",
              "      <td>0.687472</td>\n",
              "      <td>0.684617</td>\n",
              "      <td>0.706855</td>\n",
              "      <td>0.704992</td>\n",
              "      <td>0.699998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.485300</td>\n",
              "      <td>1.013008</td>\n",
              "      <td>0.708444</td>\n",
              "      <td>0.697068</td>\n",
              "      <td>0.692654</td>\n",
              "      <td>0.692173</td>\n",
              "      <td>0.709277</td>\n",
              "      <td>0.708444</td>\n",
              "      <td>0.706240</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1062, training_loss=0.5712700859975006, metrics={'train_runtime': 278.2826, 'train_samples_per_second': 121.97, 'train_steps_per_second': 3.816, 'total_flos': 4471704649125120.0, 'train_loss': 0.5712700859975006, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the best model\n",
        "%cd '/content/drive/MyDrive/TextMining'\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7DaTRZHjw-G",
        "outputId": "9a9cc978-344d-4a51-921c-9183267f4e96"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TextMining\n",
            " baseline_sample_imdb_nb_svm.ipynb      labels_train.pickle\n",
            " bert_sentiment_class.ipynb             movie_clustering_agglomerative.ipynb\n",
            " \u001b[0m\u001b[01;34mBestModel_20news\u001b[0m/                      movie_clustering.ipynb\n",
            " bulletin_hofstra_extract_html.ipynb    movie_clustering_large.ipynb\n",
            " counter_movies_F24.npz                 movie_clustering_notebook.ipynb\n",
            " count_vectorizer_movies_F24.pkl        movie_clustering_notebook_start.ipynb\n",
            " count_vect_top20                       movie_embed.npy\n",
            " count_vect_top20.pkl                   movie_feedback_retrieval.ipynb\n",
            " \u001b[01;34mDataSets\u001b[0m/                              naive_bayes_20_news.ipynb\n",
            " demo_spacy.ipynb                       naive_bayes_sentiment_class.ipynb\n",
            " encoder_classification_example.ipynb   naive_bayes_start.ipynb\n",
            " example_tf_idf.py                      notebook1_nlp_intro.ipynb\n",
            " faiss.ipynb                            page_rank.ipynb\n",
            " feedback_retrieval_class.ipynb         probabilistic.ipynb\n",
            " file_counter.pkl                       processed_test_reviews.pickle\n",
            " file_terms.pkl                         processed_train_reviews.pickle\n",
            " file_tokens.pkl                       'read_inaugural_addresses (1).ipynb'\n",
            " full_imdb_data_nb_svm.ipynb            read_inaugural_addresses.ipynb\n",
            " gen_synonyms.ipynb                     README.md\n",
            " indexing_class.ipynb                   sample_rag.ipynb\n",
            " indexing_F25.ipynb                     sentence_transformers.ipynb\n",
            " information_retrieval_graph.graphml    wiki_movie_plots_deduped.csv\n",
            " labels_test.pickle                     wiki_movie_plots_deduped.gsheet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"BestModel_20news/best_model\")"
      ],
      "metadata": {
        "id": "8Ut0-i-wk1xb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls \"BestModel_20news/best_model\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0AHUfGdlY8n",
        "outputId": "65bc4142-f490-465f-e7c0-1f2e8b0a1063"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json        special_tokens_map.json  tokenizer.json     vocab.txt\n",
            "model.safetensors  tokenizer_config.json    training_args.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load saved model\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"BestModel_20news/best_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"BestModel_20news/best_model\")"
      ],
      "metadata": {
        "id": "E8K6-yMWlsQ1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test = trainer.evaluate(test_token)"
      ],
      "metadata": {
        "id": "yYZhTDfWtDc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5QcyyzAtHuP",
        "outputId": "63ea4e77-67e0-4d17-9808-e81720a136aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 1.0916513204574585,\n",
              " 'eval_model_preparation_time': 0.0019,\n",
              " 'eval_accuracy': 0.6999468932554435,\n",
              " 'eval_precision_macro': 0.6922633096542422,\n",
              " 'eval_recall_macro': 0.6871934053776215,\n",
              " 'eval_f1_macro': 0.6867454716417745,\n",
              " 'eval_precision_weighted': 0.7037363387876138,\n",
              " 'eval_recall_weighted': 0.6999468932554435,\n",
              " 'eval_f1_weighted': 0.6990686497621589,\n",
              " 'eval_runtime': 9.4774,\n",
              " 'eval_samples_per_second': 397.367,\n",
              " 'eval_steps_per_second': 6.225}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load inference pipeline directly\n",
        "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "#text = \"Carlos Alcaraz stays perfect at ATP Finals with thrilling win over Taylor Fritz.\"\n",
        "#text = \"Carolina Hurricanes defenseman Charles Alexis Legault is recovering from surgery to repair lacerations to his hand from a skate blade, the team said Tuesday.\"\n",
        "text = \"What should i buy, a PC or a mac?\"\n",
        "result = classifier(text)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh3OjuJLl7QD",
        "outputId": "46d362f0-0cf2-4353-f4f5-ffdf30280e71"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'comp.sys.mac.hardware', 'score': 0.6038538813591003}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 8) Save final model\n",
        "trainer.save_model(\"final_model\")"
      ],
      "metadata": {
        "id": "K2Fhlin6sVuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_AzADJQBmjp",
        "outputId": "c0ee5149-cc92-4c1d-b231-95cfe9e9f6ba"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'alt.atheism',\n",
              " 1: 'comp.graphics',\n",
              " 2: 'comp.os.ms-windows.misc',\n",
              " 3: 'comp.sys.ibm.pc.hardware',\n",
              " 4: 'comp.sys.mac.hardware',\n",
              " 5: 'comp.windows.x',\n",
              " 6: 'misc.forsale',\n",
              " 7: 'rec.autos',\n",
              " 8: 'rec.motorcycles',\n",
              " 9: 'rec.sport.baseball',\n",
              " 10: 'rec.sport.hockey',\n",
              " 11: 'sci.crypt',\n",
              " 12: 'sci.electronics',\n",
              " 13: 'sci.med',\n",
              " 14: 'sci.space',\n",
              " 15: 'soc.religion.christian',\n",
              " 16: 'talk.politics.guns',\n",
              " 17: 'talk.politics.mideast',\n",
              " 18: 'talk.politics.misc',\n",
              " 19: 'talk.religion.misc'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "puiGVplNBoLe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}