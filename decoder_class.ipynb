{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOsU+nEkCcyq2aDW0mZjljI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HofstraDoboli/TextMining/blob/main/decoder_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder example for text classification - 20K news"
      ],
      "metadata": {
        "id": "i0OcLe7Fe3ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTORCH_CUDA_ALLOC_CONF = max_split_size_mb:128 # or expandable_segments:True"
      ],
      "metadata": {
        "id": "hqwdNf0Z-rqs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zNaJlxHeUVJ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets --upgrade\n",
        "!pip install transformers[torch]\n",
        "!pip install evaluate\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/TextMining/\n"
      ],
      "metadata": {
        "id": "cyNCTos-fbrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text classification reuters dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from pprint import pprint\n",
        "from datasets import Dataset\n",
        "\n",
        "#train_data    = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), shuffle=True)\n",
        "test_all_data = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), shuffle=True)\n",
        "\n",
        "#train_ds    = Dataset.from_dict({\"text\": train_data.data, \"label_id\": train_data.target})\n",
        "test_all_ds = Dataset.from_dict({\"text\": test_all_data.data, \"label\": test_all_data.target})"
      ],
      "metadata": {
        "id": "7JZ0g3l2flx5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cde84561",
        "outputId": "ef787e98-53be-43a4-9b59-18940bda0ccb"
      },
      "source": [
        "text_lengths = [len(text) for text in test_all_ds['text']]\n",
        "\n",
        "average_length = sum(text_lengths) / len(text_lengths)\n",
        "min_length = min(text_lengths)\n",
        "max_length = max(text_lengths)\n",
        "\n",
        "print(f\"Average text length: {average_length:.2f}\")\n",
        "print(f\"Minimum text length: {min_length}\")\n",
        "print(f\"Maximum text length: {max_length}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average text length: 1096.86\n",
            "Minimum text length: 0\n",
            "Maximum text length: 158791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the test_all data into validation and testing data\n",
        "test_all_split = test_all_ds.train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "val_ds  = test_all_split['train']\n",
        "test_ds = test_all_split['test']\n",
        "\n",
        "# Print the sizes of the new sets\n",
        "print(f\"Validation set size: {len(val_ds)}\")\n",
        "print(f\"Testing set size: {len(test_ds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD-7zRjngIyI",
        "outputId": "a461c91c-d980-4938-c538-1dd0af17d97f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set size: 3766\n",
            "Testing set size: 3766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6962ae04"
      },
      "source": [
        "def truncate_text(example):\n",
        "    example['text'] = example['text'][:3000]\n",
        "    return example\n",
        "\n",
        "test_ds = test_ds.map(truncate_text)\n",
        "print(f\"Example of truncated text: {test_ds['text'][0][:100]}...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detect all labels\n",
        "labels = test_all_data.target_names\n",
        "num_labels = len(labels)\n",
        "print(labels)\n",
        "print(num_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFRHr8zFgNKQ",
        "outputId": "e4caa2dc-9057-4068-f155-fdec25865ece"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i: name for i, name in enumerate(labels)}\n",
        "label2id = {name: i for i, name in enumerate(labels)}"
      ],
      "metadata": {
        "id": "eOYRIOBe1heW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "from difflib import get_close_matches # function that gets the string with the closest match\n",
        "import math, sys, os\n",
        "import torch\n",
        "\n",
        "MODEL = \"nvidia/Llama-3.1-Minitron-4B-Width-Base\" # \"google/gemma-3-1b-it\" # \"google/flan-t5-small\"   # try \"google/flan-t5-base\"\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# load tokenizer + model (adjust load flags depending on memory)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True, padding_side = 'left')\n",
        "\n",
        "# ensure pad token exists for the pipeline\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Try to load in fp16 on GPU; fallback to CPU if not available\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL,\n",
        "        device_map=\"auto\",\n",
        "        dtype= torch.float16,    # requires CUDA + GPU with half precision support\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(\"FP16 load failed, trying default dtype:\", e)\n",
        "    model = AutoModelForCausalLM.from_pretrained(MODEL, device_map=\"auto\")\n",
        "\n",
        "# Create a text-generation pipeline (spe)\n",
        "gen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "bhCfmlC8fugo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = gen('How are you doing: Answer')\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMrPs0er0Lij",
        "outputId": "a40204e1-16a1-409b-a7a1-5784c6e83b3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"How are you doing: Answered\\n\\nWhat are some of the things you like to do for fun? What are some of the things you don't like to do? How do you like to spend your time off from school? When you are home on a day off, what are you likely to be doing? How about on the weekend? What do you like to do on the weekend? What do you like to do at night? How about in your free time? How do you like to spend your time when you are not at school or work?\\n\\nIf you could do anything, what would you want to do? What is the most interesting thing you have ever done? What is the most unusual thing you have ever done? What do you think is the most interesting thing someone has ever done? What is the strangest thing you have ever done? What is the most unusual thing you have ever seen? What is the most unusual thing you have ever eaten? What is the most unusual thing you have ever worn? What is the most unusual thing you have ever done, but you want to do again? What is the most unusual thing you have ever done that you do not want to do again? What is the most unusual thing you have ever seen? What is the most unusual thing you have ever\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "print(\"CUDA device:\", torch.cuda.current_device())\n",
        "print(torch.cuda.memory_summary(device=torch.cuda.current_device(), abbreviated=False))\n",
        "# dtype check\n",
        "import itertools\n",
        "print(\"param dtype:\", next(iter(model.parameters())).dtype)"
      ],
      "metadata": {
        "id": "NX_e66AMjSdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_kwargs = dict(\n",
        "    max_new_tokens = 5,\n",
        "    do_sample = False,    # greedy\n",
        "    temperature=0.0,      # deterministic\n",
        "    top_k=10,              # effectively argmax\n",
        "    top_p=0.9,\n",
        "    eos_token_id = None,  # let pipeline handle end; you will need to strip results\n",
        "    stop_sequence = '\\n',\n",
        "    #max_length = 2048,      # Add max_length to truncate long inputs - does not work with both\n",
        "    truncation = True,\n",
        "    padding = True,\n",
        "    use_cache = False\n",
        ")"
      ],
      "metadata": {
        "id": "RJCAc3MNgcqZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt_zero_shot(text, labels):\n",
        "    labels_str = \", \".join(labels)   # short comma-separated label names\n",
        "    prompt = (\n",
        "        \"You are a news classifier. Choose exactly one topic from the list below \"\n",
        "        \"and respond with exactly that label (nothing else).\\n\\n\"\n",
        "        f\"Labels: {labels_str}\\n\\n\"\n",
        "        f\"Text: {text}\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "prompt = build_prompt_zero_shot(test_ds['text'][0], labels)\n",
        "#print(prompt)\n",
        "output = gen(prompt,**gen_kwargs)\n",
        "print(output[0]['generated_text'])\n",
        "print('\\n\\n')\n",
        "print(output[0]['generated_text'].split('Answer:')[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5nVdsxzgS7t",
        "outputId": "911461fe-b132-4a41-98b0-da69eb3d9009"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a news classifier. Choose exactly one topic from the list below and respond with exactly that label (nothing else).\n",
            "\n",
            "Labels: alt.atheism, comp.graphics, comp.os.ms-windows.misc, comp.sys.ibm.pc.hardware, comp.sys.mac.hardware, comp.windows.x, misc.forsale, rec.autos, rec.motorcycles, rec.sport.baseball, rec.sport.hockey, sci.crypt, sci.electronics, sci.med, sci.space, soc.religion.christian, talk.politics.guns, talk.politics.mideast, talk.politics.misc, talk.religion.misc\n",
            "\n",
            "Text: \n",
            "\n",
            "My experience is when they pound their fists on your back it means \"slow down\".\n",
            "\n",
            "Seriously, concentrate on being very smooth, and you will make her\n",
            "experience much more enjoyable.  Even a normal upshift causes your\n",
            "passenger to bob, so I ease off the throttle before pulling in the\n",
            "clutch to eliminate this.  It's more work, but your passenger will\n",
            "appreciate it!  Also, I've found that using more rear brake than normal\n",
            "helps keep the bike from diving as much during routine stops, which\n",
            "makes it much easier for the passenger to hang on.  If you're going\n",
            "sport riding, have the passenger reach around you and brace themselves\n",
            "against the tank so you don't have to bear both your weights with your\n",
            "arms.  (Again your bike will dive less too)\n",
            "\n",
            "Answer: comp.os.ms-windows.misc\n",
            "\n",
            "\n",
            "\n",
            " comp.os.ms-windows.misc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) helper to map output text -> canonical label\n",
        "def map_to_label(generated_text, label_list):\n",
        "    # basic cleaning\n",
        "    s = generated_text.strip().strip('\"').strip(\"'\")\n",
        "    # try exact case-insensitive match\n",
        "    for lab in label_list:\n",
        "        if s.lower() == lab.lower():\n",
        "            return lab\n",
        "    # try contains any label token\n",
        "    for lab in label_list:\n",
        "        if lab.lower() in s.lower():\n",
        "            return lab\n",
        "    # fuzzy fallback\n",
        "    matches = get_close_matches(s, label_list, n=1, cutoff=0.5)\n",
        "    if matches:\n",
        "      return matches[0]\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "pred_label = map_to_label(output[0]['generated_text'].split('Answer:')[1], labels)\n",
        "print(pred_label)"
      ],
      "metadata": {
        "id": "ROHJFb_oglsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781dcb2c-daec-402e-f917-79c8f133b03b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.os.ms-windows.misc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def print_mem(tag=\"\"): # displays the current memory usage\n",
        "    dev = torch.cuda.current_device()\n",
        "    print(f\"[{time.strftime('%H:%M:%S')}] {tag} allocated={torch.cuda.memory_allocated(dev)/(1024**3):.3f} GiB \"\n",
        "          f\"reserved={torch.cuda.memory_reserved(dev)/(1024**3):.3f} GiB max={torch.cuda.max_memory_allocated(dev)/(1024**3):.3f} GiB\")\n"
      ],
      "metadata": {
        "id": "RUNNw7uQ-JG5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = []\n",
        "true_labels = []\n",
        "batch_size = 4 # This batch_size will now be used by the pipeline internally\n",
        "\n",
        "# Limit the dataset to the first 32 examples for this evaluation run, as per original code.\n",
        "eval_dataset_subset = test_ds # range(32))\n",
        "# Extract true labels for the subset\n",
        "true_labels.extend([label for label in eval_dataset_subset['label']])\n",
        "\n",
        "num_batches = math.ceil(len(eval_dataset_subset) / batch_size)\n",
        "\n",
        "for i in range(num_batches):\n",
        "    print_mem(f\"before batch {i}\")\n",
        "    print('Batch', i+1)\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min(start_idx + batch_size, len(eval_dataset_subset))\n",
        "    batch =    eval_dataset_subset[start_idx:end_idx]\n",
        "    prompts = [build_prompt_zero_shot(text, labels) for text in batch[\"text\"]]\n",
        "\n",
        "    outs = gen(prompts, **gen_kwargs, batch_size=batch_size)\n",
        "\n",
        "    for output_per_prompt in outs:\n",
        "        full_generated_text = output_per_prompt[0][\"generated_text\"]\n",
        "        if \"Answer:\" in full_generated_text:\n",
        "            gen_part = full_generated_text.split(\"Answer:\", 1)[1].strip()\n",
        "            pred_label = map_to_label(gen_part, labels)\n",
        "            preds.append(pred_label if pred_label is not None else \"UNMAPPED\")\n",
        "        else:\n",
        "            print(\"Answer not found in the generated text\")\n",
        "            preds.append(\"UNMAPPED\") # Append UNMAPPED if answer not found\n",
        "\n",
        "    print_mem(f\"after gen batch {i}\")\n",
        "    del outs, prompts, batch\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print_mem(f\"after cleanup batch {i}\")\n"
      ],
      "metadata": {
        "id": "L-fiHvHu3gmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_ds['text'][40]))\n",
        "# print the length of each text in test_ds between index 40 and 50\n",
        "print([len(test_ds['text'][i]) for i in range(40, 50)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnldcMHAEGy",
        "outputId": "144ef88d-8cba-468f-f05e-f58354498a0e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226\n",
            "[226, 91, 0, 158791, 380, 172, 579, 76, 754, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -a"
      ],
      "metadata": {
        "id": "qzNhLZVv95hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"allocated:\", torch.cuda.memory_allocated()/(1024**3), \"GiB\")\n",
        "print(\"reserved: \", torch.cuda.memory_reserved()/(1024**3), \"GiB\")\n",
        "print(\"max_alloc: \", torch.cuda.max_memory_allocated()/(1024**3), \"GiB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkP6WIlM9mRb",
        "outputId": "393ad4f1-5440-4e9d-8429-0d9290a90a75"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allocated: 8.413580417633057 GiB\n",
            "reserved:  8.462890625 GiB\n",
            "max_alloc:  9.120858669281006 GiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds)\n",
        "print(len(preds))\n",
        "true_named_labels = [labels[i] for i in true_labels]\n",
        "#print(true_named_labels)"
      ],
      "metadata": {
        "id": "Kqh5_ZLa6NZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the acuracy of the classifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy = accuracy_score(true_named_labels, preds)\n",
        "# compute accuracy per class\n",
        "report = classification_report(true_named_labels, preds)\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R5CiA3n1van",
        "outputId": "989af8d0-8fb8-4db1-9373-5a4ae321c6c2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                UNMAPPED       0.00      0.00      0.00         0\n",
            "             alt.atheism       0.15      0.10      0.12       158\n",
            "           comp.graphics       0.61      0.42      0.50       198\n",
            " comp.os.ms-windows.misc       0.06      0.72      0.11       210\n",
            "comp.sys.ibm.pc.hardware       0.24      0.29      0.26       181\n",
            "   comp.sys.mac.hardware       0.82      0.27      0.41       197\n",
            "          comp.windows.x       0.50      0.02      0.04       197\n",
            "            misc.forsale       0.00      0.00      0.00       201\n",
            "               rec.autos       0.08      0.07      0.08       184\n",
            "         rec.motorcycles       1.00      0.02      0.04       188\n",
            "      rec.sport.baseball       0.12      0.14      0.13       186\n",
            "        rec.sport.hockey       0.78      0.10      0.18       205\n",
            "               sci.crypt       1.00      0.01      0.02       193\n",
            "         sci.electronics       1.00      0.01      0.02       210\n",
            "                 sci.med       0.67      0.05      0.10       195\n",
            "               sci.space       1.00      0.06      0.11       197\n",
            "  soc.religion.christian       0.50      0.00      0.01       208\n",
            "      talk.politics.guns       0.00      0.00      0.00       182\n",
            "   talk.politics.mideast       0.00      0.00      0.00       192\n",
            "      talk.politics.misc       0.00      0.00      0.00       154\n",
            "      talk.religion.misc       1.00      0.01      0.02       130\n",
            "\n",
            "                accuracy                           0.12      3766\n",
            "               macro avg       0.45      0.11      0.10      3766\n",
            "            weighted avg       0.48      0.12      0.11      3766\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f435fb11",
        "outputId": "72483479-3fab-435d-8964-4a3d9c1a5843"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure true_named_labels corresponds to the evaluated subset\n",
        "true_named_labels_subset = [labels[i] for i in eval_dataset_subset['label']]\n",
        "\n",
        "# Create a DataFrame from the true and predicted labels\n",
        "predictions_df = pd.DataFrame({\n",
        "    'True Label': true_named_labels_subset,\n",
        "    'Predicted Label': preds\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "predictions_df.to_csv('predictions.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predictions.csv'\")\n",
        "print(predictions_df.head())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'predictions.csv'\n",
            "         True Label          Predicted Label\n",
            "0   rec.motorcycles  comp.os.ms-windows.misc\n",
            "1       alt.atheism                 UNMAPPED\n",
            "2      misc.forsale  comp.os.ms-windows.misc\n",
            "3     comp.graphics            comp.graphics\n",
            "4  rec.sport.hockey                 UNMAPPED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) quick display of some examples\n",
        "for i in range(10):\n",
        "    print(\"TEXT:\", test_ds['text'][i][:100].replace(\"\\n\",\" \"))\n",
        "    print(\"PRED:\", preds[i])\n",
        "    print(\"GOLD:\", labels[true_labels[i]])\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGCqubhag3f9",
        "outputId": "f857963b-f33e-47b1-c8cc-b3fa6c277ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXT:   My experience is when they pound their fists on your back it means \"slow down\".  Seriously, concen\n",
            "PRED: rec.sport.baseball\n",
            "GOLD: rec.motorcycles\n",
            "---\n",
            "TEXT: : In article <C5Mw03.9qr@darkside.osrhe.uoknor.edu>, bil@okcforum.osrhe.edu : > I'd say that what on\n",
            "PRED: misc.forsale\n",
            "GOLD: alt.atheism\n",
            "---\n",
            "TEXT: \n",
            "PRED: alt.atheism\n",
            "GOLD: misc.forsale\n",
            "---\n",
            "TEXT:     The alt.* hierarchie is created for 2 purposes: 1. For groups which do not fit under the comp.* \n",
            "PRED: comp.graphics\n",
            "GOLD: comp.graphics\n",
            "---\n",
            "TEXT: Again I assume this is not just flame bait by Roger, but actually a truly held opinion.     Thanks. \n",
            "PRED: comp.sys.ibm.pc.hardware\n",
            "GOLD: rec.sport.hockey\n",
            "---\n",
            "TEXT: I.D. Benham, on the Wed, 21 Apr 1993 17:11:39 GMT wibbled: : Hi, :    I'm now in the market for buyi\n",
            "PRED: comp.sys.ibm.pc.hardware\n",
            "GOLD: rec.motorcycles\n",
            "---\n",
            "TEXT:  Robert McElwaine is the authoritative source of scientific data on Internet. He can be reached alt.\n",
            "PRED: alt.atheism\n",
            "GOLD: sci.space\n",
            "---\n",
            "TEXT: Elias Davidsson writes...     ED> The following are quotations from Zionist leaders. They appear in \n",
            "PRED: misc.forsale\n",
            "GOLD: talk.politics.mideast\n",
            "---\n",
            "TEXT: : A woman once told me her doctor told her that I : could catch, asymptomatically, her yeast infecti\n",
            "PRED: comp.sys.ibm.pc.hardware\n",
            "GOLD: sci.med\n",
            "---\n",
            "TEXT:  I don't think the two main free X systems ( XS3 and XFree86 ) are part of the FSF as such.   Does a\n",
            "PRED: comp.os.ms-windows.misc\n",
            "GOLD: comp.sys.ibm.pc.hardware\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}