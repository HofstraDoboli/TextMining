{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2kX1/oha93G6yHbPPrg8p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HofstraDoboli/TextMining/blob/main/faiss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a0c6369"
      },
      "source": [
        "!pip install faiss-cpu sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea290d57"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Load a pre-trained model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Sample data (list of sentences)\n",
        "sentences = [\n",
        "    \"This is an example sentence\",\n",
        "    \"Each sentence is converted\",\n",
        "    \"into its corresponding embedding\",\n",
        "    \"using a pre-trained Sentence Transformer model.\"\n",
        "]\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "print(\"Embeddings generated. Shape:\", embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7981bec7",
        "outputId": "527f4b08-518c-4073-aafd-d47bc256aebc"
      },
      "source": [
        "import faiss\n",
        "\n",
        "# Dimension of the embeddings\n",
        "embedding_dimension = embeddings.shape[1]\n",
        "\n",
        "# Build a simple index (e.g., IndexFlatL2)\n",
        "index = faiss.IndexFlatL2(embedding_dimension) # FlatL2 = store the whole vector, use L2 = Euclidean distance\n",
        "\n",
        "# Add embeddings to the index\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"FAISS index created with {index.ntotal} vectors\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index created with 4 vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22f41562",
        "outputId": "40ee583e-044a-46e1-d0cb-c35f8004a2c1"
      },
      "source": [
        "# New sentences to add\n",
        "new_sentences = [\n",
        "    \"This is a new sentence\",\n",
        "    \"Adding more data to the index\"\n",
        "]\n",
        "\n",
        "# Generate embeddings for the new sentences\n",
        "new_embeddings = model.encode(new_sentences)\n",
        "\n",
        "# Add the new embeddings to the index\n",
        "index.add(new_embeddings)\n",
        "\n",
        "# Update the original sentences list to include the new ones\n",
        "sentences.extend(new_sentences)\n",
        "\n",
        "print(f\"Added {len(new_sentences)} new vectors to the index. Total vectors: {index.ntotal}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 2 new vectors to the index. Total vectors: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36979aa0",
        "outputId": "d682292a-7ada-4a2d-bf95-1e778e55c4ce"
      },
      "source": [
        "# Define a query sentence\n",
        "query_sentence = \"This is a query sentence\"\n",
        "\n",
        "# Generate embedding for the query sentence\n",
        "query_embedding = model.encode([query_sentence])\n",
        "\n",
        "# Number of nearest neighbors to retrieve\n",
        "k = 2\n",
        "\n",
        "# Search the index for the nearest neighbors\n",
        "distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "print(f\"Nearest neighbors for '{query_sentence}':\")\n",
        "for i in range(k):\n",
        "    print(f\"  Sentence: '{sentences[indices[0][i]]}' (Distance: {distances[0][i]})\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nearest neighbors for 'This is a query sentence':\n",
            "  Sentence: 'This is an example sentence' (Distance: 0.8553394079208374)\n",
            "  Sentence: 'This is a new sentence' (Distance: 1.0013540983200073)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21be0552"
      },
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Normalize the existing embeddings (L2 normalization)\n",
        "normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "# Dimension of the embeddings\n",
        "embedding_dimension = normalized_embeddings.shape[1]\n",
        "\n",
        "# Build a new index with inner product (IndexFlatIP)\n",
        "index_ip = faiss.IndexFlatIP(embedding_dimension)\n",
        "\n",
        "# Add the normalized embeddings to the index\n",
        "index_ip.add(normalized_embeddings)\n",
        "\n",
        "print(f\"FAISS IndexFlatIP created with {index_ip.ntotal} normalized vectors\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "679ad245"
      },
      "source": [
        "# Normalize the query embedding\n",
        "normalized_query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
        "\n",
        "# Number of nearest neighbors to retrieve\n",
        "k = 2\n",
        "\n",
        "# Search the IndexFlatIP for the nearest neighbors (using inner product, which is cosine similarity here)\n",
        "distances_ip, indices_ip = index_ip.search(normalized_query_embedding, k)\n",
        "\n",
        "print(f\"Nearest neighbors for '{query_sentence}' using cosine similarity (IndexFlatIP):\")\n",
        "# Note: For IndexFlatIP with normalized vectors, higher inner product means higher similarity (closer)\n",
        "# The distances returned are the inner products.\n",
        "for i in range(k):\n",
        "    print(f\"  Sentence: '{sentences[indices_ip[0][i]]}' (Cosine Similarity: {distances_ip[0][i]})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf0f930f"
      },
      "source": [
        "# Save the index to a file\n",
        "index_filename = \"my_faiss_index.index\"\n",
        "faiss.write_index(index, index_filename)\n",
        "\n",
        "print(f\"FAISS index saved to {index_filename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "182caa75"
      },
      "source": [
        "# Load the index from a file\n",
        "loaded_index = faiss.read_index(index_filename)\n",
        "\n",
        "print(f\"FAISS index loaded from {index_filename} with {loaded_index.ntotal} vectors\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86b0b3b4"
      },
      "source": [
        "# Verify the number of vectors in the loaded index\n",
        "print(f\"Number of vectors in the loaded index: {loaded_index.ntotal}\")\n",
        "\n",
        "# You can also check the dimension of the vectors\n",
        "print(f\"Dimension of vectors in the loaded index: {loaded_index.d}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}